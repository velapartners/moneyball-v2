{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import all the libraries\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "import math\n",
    "import urllib\n",
    "import difflib \n",
    "import seaborn as sns\n",
    "import sklearn.model_selection\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Loads the dataframe of with the features'''\n",
    "df_All_Companies_merged = pd.read_pickle(r'Data\\df_All_Companies_merged_with_features.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Set the random state for reproducibility of results\n",
    "\n",
    "'''\n",
    "def set_random_state():    \n",
    "    # Seed value\n",
    "    # Apparently you may use different seed values at each stage\n",
    "    seed_value= 0\n",
    "\n",
    "    # 1. Set the `PYTHONHASHSEED` environment variable at a fixed value\n",
    "    os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "\n",
    "    # 2. Set the `python` built-in pseudo-random generator at a fixed value\n",
    "    random.seed(seed_value)\n",
    "\n",
    "    # 3. Set the `numpy` pseudo-random generator at a fixed value\n",
    "    np.random.seed(seed_value)\n",
    "\n",
    "    # 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
    "    tf.compat.v1.set_random_seed(seed_value)\n",
    "\n",
    "    # 5. Configure a new global `tensorflow` session\n",
    "    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "    tf.compat.v1.keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of data set is:  5685\n",
      "Size of successful companies in set is:  365\n",
      "Size train set is 3979 and number of successful companies in set is 255\n",
      "Size test set is 2842 and number of successful companies in set is 182\n",
      "Size validation set is 2843 and number of successful companies in set is 183\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.1211 - binary_accuracy: 0.9500\n",
      "The loss on the test set is 0.12109331786632538 and the binary accuracy is 0.9500352144241333\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 3.6342 - binary_accuracy: 0.1753\n",
      "The loss on only successful companies set is 3.6342151165008545 and the binary accuracy is 0.17534247040748596\n",
      "167/167 [==============================] - 0s 1ms/step - loss: 0.0926 - binary_accuracy: 0.9925\n",
      "The loss on only successful companies set is 0.0925748348236084 and the binary accuracy is 0.9924812316894531\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "THIS WILL TRAIN A NEURAL NETWORK USING THE GROUPINGS WE CONSTRUCTED\n",
    "1. UNIVERISITY RANKING SIGNAL\n",
    "2. EXPERIENCE SIGNAL\n",
    "3. CATEGORY OF STARTUP\n",
    "WE SHALL USE TESTING DATA, VALIDATION DATA, AND SEE THE SUCCESS RATE.\n",
    "'''\n",
    "\n",
    "\n",
    "training_params_binary = ['number_of_founders_grouping_scaling',\n",
    "                          'founders_connectedness_factor_based_on_university_grouping_scaling',\n",
    "                          'best_ranking_universities_of_founders_grouping_scaling',\n",
    "                          'best_score_universities_of_founders_grouping_scaling',\n",
    "                          'average_degree_of_founders_grouping_scaling',\n",
    "                          'number_of_prev_title_of_founders_grouping_scaling',\n",
    "                          'managerial_flag_number_of_prev_title_of_founders_grouping_scaling',\n",
    "                          'top_10_categories_flag',\n",
    "                          'top_10_category_groups_flag',\n",
    "                          'top_10_previous_companies_flag',\n",
    "                          'success_flag']\n",
    "\n",
    "df_for_binary_model_training = df_All_Companies_merged[training_params_binary].copy()\n",
    "df_for_binary_model_training = df_for_binary_model_training.dropna()\n",
    "print('Size of data set is: ', len(df_for_binary_model_training.index))\n",
    "\n",
    "y = df_for_binary_model_training.pop('success_flag').to_frame()\n",
    "print('Size of successful companies in set is: ', (np.sum(y.to_numpy())))\n",
    "X = df_for_binary_model_training\n",
    "\n",
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y,stratify=y, test_size=0.3, random_state = 0)\n",
    "X_test, X_val, y_test, y_val = sklearn.model_selection.train_test_split(X, y,stratify=y, test_size=0.5, random_state = 0)\n",
    "\n",
    "X_train, X_test, y_train, y_test = X_train.to_numpy(), X_test.to_numpy(), y_train.to_numpy(), y_test.to_numpy()\n",
    "X_val, y_val = X_val.to_numpy(), y_val.to_numpy()\n",
    "\n",
    "print('Size train set is {} and number of successful companies in set is {}'.format(len(X_train),np.sum(y_train)) )\n",
    "print('Size test set is {} and number of successful companies in set is {}'.format(len(X_test),np.sum(y_test)) )\n",
    "print('Size validation set is {} and number of successful companies in set is {}'.format(len(X_val),np.sum(y_val)) )\n",
    "\n",
    "\n",
    "number_of_classes = 1\n",
    "number_of_features = X_train.shape[1]\n",
    "model = Sequential()\n",
    "model.add(Dense(2**7, input_dim=number_of_features, activation='relu'))\n",
    "model.add(Dense(2**7, input_dim=number_of_features, activation='relu'))\n",
    "model.add(Dense(2**7, input_dim=number_of_features, activation='relu'))\n",
    "model.add(Dense(2**7, input_dim=number_of_features, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['binary_accuracy'])\n",
    "set_random_state()\n",
    "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs= 500, verbose = 0)\n",
    "\n",
    "eval = model.evaluate(x=X_test, y=y_test)\n",
    "print('The loss on the test set is {} and the binary accuracy is {}'.format(eval[0],eval[1]))\n",
    "\n",
    "df_for_binary_model_training = df_All_Companies_merged[training_params_binary][df_All_Companies_merged['success_flag'] == 1].copy()\n",
    "df_for_binary_model_training = df_for_binary_model_training.dropna()\n",
    "y = df_for_binary_model_training.pop('success_flag').to_frame()\n",
    "X = df_for_binary_model_training\n",
    "\n",
    "eval = model.evaluate(x=X.to_numpy(), y=y.to_numpy())\n",
    "print('The loss on only successful companies set is {} and the binary accuracy is {}'.format(eval[0],eval[1]))\n",
    "\n",
    "df_for_binary_model_training = df_All_Companies_merged[training_params_binary][df_All_Companies_merged['success_flag'] == 0].copy()\n",
    "df_for_binary_model_training = df_for_binary_model_training.dropna()\n",
    "y = df_for_binary_model_training.pop('success_flag').to_frame()\n",
    "X = df_for_binary_model_training\n",
    "\n",
    "eval = model.evaluate(x=X.to_numpy(), y=y.to_numpy())\n",
    "print('The loss on only unsuccessful companies set is {} and the binary accuracy is {}'.format(eval[0],eval[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of data set is:  2940\n",
      "Size of successful companies in set is:  336\n",
      "Size train set is 2058 and number of successful companies in set is 235\n",
      "Size test set is 1470 and number of successful companies in set is 168\n",
      "Size validation set is 1470 and number of successful companies in set is 168\n",
      "46/46 [==============================] - 0s 908us/step - loss: 0.0703 - binary_accuracy: 0.9585\n",
      "The loss on the test set is 0.07030022889375687 and the binary accuracy is 0.9585034251213074\n",
      "11/11 [==============================] - 0s 997us/step - loss: 4.2191 - binary_accuracy: 0.5208\n",
      "The loss on only successful companies set is 4.219130992889404 and the binary accuracy is 0.5208333134651184\n",
      "82/82 [==============================] - 0s 827us/step - loss: 0.1228 - binary_accuracy: 0.9816\n",
      "The loss on only successful companies set is 0.12279508262872696 and the binary accuracy is 0.981566846370697\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "THIS WILL TRAIN A NEURAL NETWORK USING THE GROUPINGS WE CONSTRUCTED\n",
    "1. UNIVERISITY RANKING SIGNAL\n",
    "2. EXPERIENCE SIGNAL\n",
    "3. CATEGORY OF STARTUP\n",
    "4. NUMBER OF INVERSTORS (NOT INVESTOR SUCCESS)\n",
    "\n",
    "WE SHALL USE TESTING DATA, VALIDATION DATA, AND SEE THE SUCCESS RATE.\n",
    "'''\n",
    "\n",
    "\n",
    "training_params_binary = ['number_of_founders_grouping_scaling',\n",
    "                          'founders_connectedness_factor_based_on_university_grouping_scaling',\n",
    "                          'best_ranking_universities_of_founders_grouping_scaling',\n",
    "                          'best_score_universities_of_founders_grouping_scaling',\n",
    "                          'average_degree_of_founders_grouping_scaling',\n",
    "                          'number_of_prev_title_of_founders_grouping_scaling',\n",
    "                          'managerial_flag_number_of_prev_title_of_founders_grouping_scaling',\n",
    "                          'top_10_categories_flag',\n",
    "                          'number_of_investors_grouping_scaling',\n",
    "                          'top_10_category_groups_flag',\n",
    "                          'top_10_previous_companies_flag',\n",
    "                          'success_flag']\n",
    "\n",
    "df_for_binary_model_training = df_All_Companies_merged[training_params_binary].copy()\n",
    "df_for_binary_model_training = df_for_binary_model_training.dropna()\n",
    "print('Size of data set is: ', len(df_for_binary_model_training.index))\n",
    "\n",
    "y = df_for_binary_model_training.pop('success_flag').to_frame()\n",
    "print('Size of successful companies in set is: ', (np.sum(y.to_numpy())))\n",
    "X = df_for_binary_model_training\n",
    "\n",
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y,stratify=y, test_size=0.3, random_state = 0)\n",
    "X_test, X_val, y_test, y_val = sklearn.model_selection.train_test_split(X, y,stratify=y, test_size=0.5, random_state = 0)\n",
    "\n",
    "X_train, X_test, y_train, y_test = X_train.to_numpy(), X_test.to_numpy(), y_train.to_numpy(), y_test.to_numpy()\n",
    "X_val, y_val = X_val.to_numpy(), y_val.to_numpy()\n",
    "\n",
    "print('Size train set is {} and number of successful companies in set is {}'.format(len(X_train),np.sum(y_train)) )\n",
    "print('Size test set is {} and number of successful companies in set is {}'.format(len(X_test),np.sum(y_test)) )\n",
    "print('Size validation set is {} and number of successful companies in set is {}'.format(len(X_val),np.sum(y_val)) )\n",
    "\n",
    "\n",
    "number_of_classes = 1\n",
    "number_of_features = X_train.shape[1]\n",
    "model = Sequential()\n",
    "model.add(Dense(2**7, input_dim=number_of_features, activation='relu'))\n",
    "model.add(Dense(2**7, input_dim=number_of_features, activation='relu'))\n",
    "model.add(Dense(2**7, input_dim=number_of_features, activation='relu'))\n",
    "model.add(Dense(2**7, input_dim=number_of_features, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['binary_accuracy'])\n",
    "set_random_state()\n",
    "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs= 500, verbose = 0)\n",
    "\n",
    "eval = model.evaluate(x=X_test, y=y_test)\n",
    "print('The loss on the test set is {} and the binary accuracy is {}'.format(eval[0],eval[1]))\n",
    "\n",
    "df_for_binary_model_training = df_All_Companies_merged[training_params_binary][df_All_Companies_merged['success_flag'] == 1].copy()\n",
    "df_for_binary_model_training = df_for_binary_model_training.dropna()\n",
    "y = df_for_binary_model_training.pop('success_flag').to_frame()\n",
    "X = df_for_binary_model_training\n",
    "\n",
    "eval = model.evaluate(x=X.to_numpy(), y=y.to_numpy())\n",
    "print('The loss on only successful companies set is {} and the binary accuracy is {}'.format(eval[0],eval[1]))\n",
    "\n",
    "df_for_binary_model_training = df_All_Companies_merged[training_params_binary][df_All_Companies_merged['success_flag'] == 0].copy()\n",
    "df_for_binary_model_training = df_for_binary_model_training.dropna()\n",
    "y = df_for_binary_model_training.pop('success_flag').to_frame()\n",
    "X = df_for_binary_model_training\n",
    "\n",
    "eval = model.evaluate(x=X.to_numpy(), y=y.to_numpy())\n",
    "print('The loss on only successful companies set is {} and the binary accuracy is {}'.format(eval[0],eval[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of data set is:  2940\n",
      "Size of successful companies in set is:  336\n",
      "Size train set is 2058 and number of successful companies in set is 235\n",
      "Size test set is 1470 and number of successful companies in set is 168\n",
      "Size validation set is 1470 and number of successful companies in set is 168\n",
      "46/46 [==============================] - 0s 866us/step - loss: 0.0017 - binary_accuracy: 1.0000\n",
      "The loss on the test set is 0.0017450465820729733 and the binary accuracy is 1.0\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.5651 - binary_accuracy: 0.9286\n",
      "The loss on only successful companies set is 0.5650855898857117 and the binary accuracy is 0.9285714030265808\n",
      "82/82 [==============================] - 0s 988us/step - loss: 0.0447 - binary_accuracy: 0.9950\n",
      "The loss on only successful companies set is 0.044740449637174606 and the binary accuracy is 0.9950076937675476\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "THIS WILL TRAIN A NEURAL NETWORK USING THE GROUPINGS WE CONSTRUCTED\n",
    "1. UNIVERISITY RANKING SIGNAL\n",
    "2. EXPERIENCE SIGNAL\n",
    "3. CATEGORY OF STARTUP\n",
    "4. NUMBER OF INVERSTORS (AND INVESTOR SUCCESS)\n",
    "\n",
    "WE SHALL USE TESTING DATA, VALIDATION DATA, AND SEE THE SUCCESS RATE.\n",
    "'''\n",
    "\n",
    "\n",
    "training_params_binary = ['number_of_founders_grouping_scaling',\n",
    "                          'founders_connectedness_factor_based_on_university_grouping_scaling',\n",
    "                          'best_ranking_universities_of_founders_grouping_scaling',\n",
    "                          'best_score_universities_of_founders_grouping_scaling',\n",
    "                          'average_degree_of_founders_grouping_scaling',\n",
    "                          'number_of_prev_title_of_founders_grouping_scaling',\n",
    "                          'managerial_flag_number_of_prev_title_of_founders_grouping_scaling',\n",
    "                          'top_10_categories_flag',\n",
    "                          'number_of_investors_grouping_scaling',\n",
    "                          'average_investor_success',\n",
    "                          'top_10_category_groups_flag',\n",
    "                          'top_10_previous_companies_flag',\n",
    "                          'success_flag']\n",
    "\n",
    "df_for_binary_model_training = df_All_Companies_merged[training_params_binary].copy()\n",
    "df_for_binary_model_training = df_for_binary_model_training.dropna()\n",
    "print('Size of data set is: ', len(df_for_binary_model_training.index))\n",
    "\n",
    "y = df_for_binary_model_training.pop('success_flag').to_frame()\n",
    "print('Size of successful companies in set is: ', (np.sum(y.to_numpy())))\n",
    "X = df_for_binary_model_training\n",
    "\n",
    "X_train, X_test, y_train,  y_test = sklearn.model_selection.train_test_split(X, y,stratify=y, test_size=0.3, random_state = 0)\n",
    "X_test, X_val, y_test, y_val = sklearn.model_selection.train_test_split(X, y,stratify=y, test_size=0.5, random_state = 0)\n",
    "\n",
    "X_train, X_test, y_train, y_test = X_train.to_numpy(), X_test.to_numpy(), y_train.to_numpy(), y_test.to_numpy()\n",
    "X_val, y_val = X_val.to_numpy(), y_val.to_numpy()\n",
    "\n",
    "print('Size train set is {} and number of successful companies in set is {}'.format(len(X_train),np.sum(y_train)) )\n",
    "print('Size test set is {} and number of successful companies in set is {}'.format(len(X_test),np.sum(y_test)) )\n",
    "print('Size validation set is {} and number of successful companies in set is {}'.format(len(X_val),np.sum(y_val)) )\n",
    "\n",
    "\n",
    "number_of_classes = 1\n",
    "number_of_features = X_train.shape[1]\n",
    "model = Sequential()\n",
    "model.add(Dense(2**7, input_dim=number_of_features, activation='relu'))\n",
    "model.add(Dense(2**7, input_dim=number_of_features, activation='relu'))\n",
    "model.add(Dense(2**7, input_dim=number_of_features, activation='relu'))\n",
    "model.add(Dense(2**7, input_dim=number_of_features, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['binary_accuracy'])\n",
    "set_random_state()\n",
    "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs= 500, verbose = 0)\n",
    "\n",
    "eval = model.evaluate(x=X_test, y=y_test)\n",
    "print('The loss on the test set is {} and the binary accuracy is {}'.format(eval[0],eval[1]))\n",
    "\n",
    "df_for_binary_model_training = df_All_Companies_merged[training_params_binary][df_All_Companies_merged['success_flag'] == 1].copy()\n",
    "df_for_binary_model_training = df_for_binary_model_training.dropna()\n",
    "y = df_for_binary_model_training.pop('success_flag').to_frame()\n",
    "X = df_for_binary_model_training\n",
    "\n",
    "eval = model.evaluate(x=X.to_numpy(), y=y.to_numpy())\n",
    "print('The loss on only successful companies set is {} and the binary accuracy is {}'.format(eval[0],eval[1]))\n",
    "\n",
    "df_for_binary_model_training = df_All_Companies_merged[training_params_binary][df_All_Companies_merged['success_flag'] == 0].copy()\n",
    "df_for_binary_model_training = df_for_binary_model_training.dropna()\n",
    "y = df_for_binary_model_training.pop('success_flag').to_frame()\n",
    "X = df_for_binary_model_training\n",
    "\n",
    "eval = model.evaluate(x=X.to_numpy(), y=y.to_numpy())\n",
    "print('The loss on only unsuccessful companies set is {} and the binary accuracy is {}'.format(eval[0],eval[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of data set is:  10305\n",
      "Size of successful companies in set is:  482\n",
      "Size train set is 7213 and number of successful companies in set is 337\n",
      "Size test set is 5152 and number of successful companies in set is 241\n",
      "Size validation set is 5153 and number of successful companies in set is 241\n",
      "161/161 [==============================] - 0s 1ms/step - loss: 0.1315 - binary_accuracy: 0.9561\n",
      "The loss on the test set is 0.13147087395191193 and the binary accuracy is 0.9561335444450378\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 4.9537 - binary_accuracy: 0.0602\n",
      "The loss on only successful companies set is 4.953701019287109 and the binary accuracy is 0.060165975242853165\n",
      "307/307 [==============================] - 0s 915us/step - loss: 0.0503 - binary_accuracy: 0.9984\n",
      "The loss on only unsuccessful companies set is 0.050279807299375534 and the binary accuracy is 0.9983711838722229\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "THIS WILL TRAIN A NEURAL NETWORK USING THE GROUPINGS WE CONSTRUCTED\n",
    "1. UNIVERISITY RANKING SIGNAL\n",
    "2. EXPERIENCE SIGNAL\n",
    "3. CATEGORY OF STARTUP\n",
    "WE SHALL USE TESTING DATA, VALIDATION DATA, AND SEE THE SUCCESS RATE.\n",
    "'''\n",
    "\n",
    "\n",
    "training_params_binary = ['number_of_founders_grouping_scaling',\n",
    "                          'best_ranking_universities_of_founders_grouping_scaling',\n",
    "                          'best_score_universities_of_founders_grouping_scaling',\n",
    "                          'average_degree_of_founders_grouping_scaling',\n",
    "                          'number_of_prev_title_of_founders_grouping_scaling',\n",
    "                          'managerial_flag_number_of_prev_title_of_founders_grouping_scaling',\n",
    "                          'top_10_categories_flag',\n",
    "                          'top_10_category_groups_flag',\n",
    "                          'top_10_previous_companies_flag',\n",
    "                          'success_flag']\n",
    "\n",
    "df_for_binary_model_training = df_All_Companies_merged[training_params_binary].copy()\n",
    "df_for_binary_model_training = df_for_binary_model_training.dropna()\n",
    "print('Size of data set is: ', len(df_for_binary_model_training.index))\n",
    "\n",
    "y = df_for_binary_model_training.pop('success_flag').to_frame()\n",
    "print('Size of successful companies in set is: ', (np.sum(y.to_numpy())))\n",
    "X = df_for_binary_model_training\n",
    "\n",
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y,stratify=y, test_size=0.3, random_state = 0)\n",
    "X_test, X_val, y_test, y_val = sklearn.model_selection.train_test_split(X, y,stratify=y, test_size=0.5, random_state = 0)\n",
    "\n",
    "X_train, X_test, y_train, y_test = X_train.to_numpy(), X_test.to_numpy(), y_train.to_numpy(), y_test.to_numpy()\n",
    "X_val, y_val = X_val.to_numpy(), y_val.to_numpy()\n",
    "\n",
    "print('Size train set is {} and number of successful companies in set is {}'.format(len(X_train),np.sum(y_train)) )\n",
    "print('Size test set is {} and number of successful companies in set is {}'.format(len(X_test),np.sum(y_test)) )\n",
    "print('Size validation set is {} and number of successful companies in set is {}'.format(len(X_val),np.sum(y_val)) )\n",
    "\n",
    "\n",
    "number_of_classes = 1\n",
    "number_of_features = X_train.shape[1]\n",
    "model = Sequential()\n",
    "model.add(Dense(2**7, input_dim=number_of_features, activation='relu'))\n",
    "model.add(Dense(2**7, input_dim=number_of_features, activation='relu'))\n",
    "model.add(Dense(2**7, input_dim=number_of_features, activation='relu'))\n",
    "model.add(Dense(2**7, input_dim=number_of_features, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['binary_accuracy'])\n",
    "set_random_state()\n",
    "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs= 500, verbose = 0)\n",
    "\n",
    "eval = model.evaluate(x=X_test, y=y_test)\n",
    "print('The loss on the test set is {} and the binary accuracy is {}'.format(eval[0],eval[1]))\n",
    "\n",
    "df_for_binary_model_training = df_All_Companies_merged[training_params_binary][df_All_Companies_merged['success_flag'] == 1].copy()\n",
    "df_for_binary_model_training = df_for_binary_model_training.dropna()\n",
    "y = df_for_binary_model_training.pop('success_flag').to_frame()\n",
    "X = df_for_binary_model_training\n",
    "\n",
    "eval = model.evaluate(x=X.to_numpy(), y=y.to_numpy())\n",
    "print('The loss on only successful companies set is {} and the binary accuracy is {}'.format(eval[0],eval[1]))\n",
    "\n",
    "df_for_binary_model_training = df_All_Companies_merged[training_params_binary][df_All_Companies_merged['success_flag'] == 0].copy()\n",
    "df_for_binary_model_training = df_for_binary_model_training.dropna()\n",
    "y = df_for_binary_model_training.pop('success_flag').to_frame()\n",
    "X = df_for_binary_model_training\n",
    "\n",
    "eval = model.evaluate(x=X.to_numpy(), y=y.to_numpy())\n",
    "print('The loss on only unsuccessful companies set is {} and the binary accuracy is {}'.format(eval[0],eval[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of data set is:  4687\n",
      "Size of successful companies in set is:  437\n",
      "Size train set is 3280 and number of successful companies in set is 306\n",
      "Size test set is 2343 and number of successful companies in set is 218\n",
      "Size validation set is 2344 and number of successful companies in set is 219\n",
      "74/74 [==============================] - 0s 930us/step - loss: 0.1166 - binary_accuracy: 0.9449\n",
      "The loss on the test set is 0.11661003530025482 and the binary accuracy is 0.9449423551559448\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 5.0006 - binary_accuracy: 0.3478\n",
      "The loss on only successful companies set is 5.000645160675049 and the binary accuracy is 0.3478260934352875\n",
      "133/133 [==============================] - 0s 858us/step - loss: 0.1203 - binary_accuracy: 0.9868\n",
      "The loss on only successful companies set is 0.12026509642601013 and the binary accuracy is 0.986823558807373\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "THIS WILL TRAIN A NEURAL NETWORK USING THE GROUPINGS WE CONSTRUCTED\n",
    "1. UNIVERISITY RANKING SIGNAL\n",
    "2. EXPERIENCE SIGNAL\n",
    "3. CATEGORY OF STARTUP\n",
    "4. NUMBER OF INVERSTORS (NOT INVESTOR SUCCESS)\n",
    "\n",
    "WE SHALL USE TESTING DATA, VALIDATION DATA, AND SEE THE SUCCESS RATE.\n",
    "'''\n",
    "\n",
    "\n",
    "training_params_binary = ['number_of_founders_grouping_scaling',\n",
    "                          'best_ranking_universities_of_founders_grouping_scaling',\n",
    "                          'best_score_universities_of_founders_grouping_scaling',\n",
    "                          'average_degree_of_founders_grouping_scaling',\n",
    "                          'number_of_prev_title_of_founders_grouping_scaling',\n",
    "                          'managerial_flag_number_of_prev_title_of_founders_grouping_scaling',\n",
    "                          'top_10_categories_flag',\n",
    "                          'number_of_investors_grouping_scaling',\n",
    "                          'top_10_category_groups_flag',\n",
    "                          'top_10_previous_companies_flag',\n",
    "                          'success_flag']\n",
    "\n",
    "df_for_binary_model_training = df_All_Companies_merged[training_params_binary].copy()\n",
    "df_for_binary_model_training = df_for_binary_model_training.dropna()\n",
    "print('Size of data set is: ', len(df_for_binary_model_training.index))\n",
    "\n",
    "y = df_for_binary_model_training.pop('success_flag').to_frame()\n",
    "print('Size of successful companies in set is: ', (np.sum(y.to_numpy())))\n",
    "X = df_for_binary_model_training\n",
    "\n",
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y,stratify=y, test_size=0.3, random_state = 0)\n",
    "X_test, X_val, y_test, y_val = sklearn.model_selection.train_test_split(X, y,stratify=y, test_size=0.5, random_state = 0)\n",
    "\n",
    "X_train, X_test, y_train, y_test = X_train.to_numpy(), X_test.to_numpy(), y_train.to_numpy(), y_test.to_numpy()\n",
    "X_val, y_val = X_val.to_numpy(), y_val.to_numpy()\n",
    "\n",
    "print('Size train set is {} and number of successful companies in set is {}'.format(len(X_train),np.sum(y_train)) )\n",
    "print('Size test set is {} and number of successful companies in set is {}'.format(len(X_test),np.sum(y_test)) )\n",
    "print('Size validation set is {} and number of successful companies in set is {}'.format(len(X_val),np.sum(y_val)) )\n",
    "\n",
    "\n",
    "number_of_classes = 1\n",
    "number_of_features = X_train.shape[1]\n",
    "model = Sequential()\n",
    "model.add(Dense(2**7, input_dim=number_of_features, activation='relu'))\n",
    "model.add(Dense(2**7, input_dim=number_of_features, activation='relu'))\n",
    "model.add(Dense(2**7, input_dim=number_of_features, activation='relu'))\n",
    "model.add(Dense(2**7, input_dim=number_of_features, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['binary_accuracy'])\n",
    "set_random_state()\n",
    "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs= 500, verbose = 0)\n",
    "\n",
    "eval = model.evaluate(x=X_test, y=y_test)\n",
    "print('The loss on the test set is {} and the binary accuracy is {}'.format(eval[0],eval[1]))\n",
    "\n",
    "df_for_binary_model_training = df_All_Companies_merged[training_params_binary][df_All_Companies_merged['success_flag'] == 1].copy()\n",
    "df_for_binary_model_training = df_for_binary_model_training.dropna()\n",
    "y = df_for_binary_model_training.pop('success_flag').to_frame()\n",
    "X = df_for_binary_model_training\n",
    "\n",
    "eval = model.evaluate(x=X.to_numpy(), y=y.to_numpy())\n",
    "print('The loss on only successful companies set is {} and the binary accuracy is {}'.format(eval[0],eval[1]))\n",
    "\n",
    "df_for_binary_model_training = df_All_Companies_merged[training_params_binary][df_All_Companies_merged['success_flag'] == 0].copy()\n",
    "df_for_binary_model_training = df_for_binary_model_training.dropna()\n",
    "y = df_for_binary_model_training.pop('success_flag').to_frame()\n",
    "X = df_for_binary_model_training\n",
    "\n",
    "eval = model.evaluate(x=X.to_numpy(), y=y.to_numpy())\n",
    "print('The loss on only successful companies set is {} and the binary accuracy is {}'.format(eval[0],eval[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of data set is:  4687\n",
      "Size of successful companies in set is:  437\n",
      "Size train set is 3280 and number of successful companies in set is 306\n",
      "Size test set is 2343 and number of successful companies in set is 218\n",
      "Size validation set is 2344 and number of successful companies in set is 219\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.0011 - binary_accuracy: 0.9987\n",
      "The loss on the test set is 0.0010925526730716228 and the binary accuracy is 0.9987195730209351\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4518 - binary_accuracy: 0.9657\n",
      "The loss on only successful companies set is 0.45184430480003357 and the binary accuracy is 0.9656750559806824\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.0824 - binary_accuracy: 0.9920\n",
      "The loss on only unsuccessful companies set is 0.08243946731090546 and the binary accuracy is 0.9919999837875366\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "THIS WILL TRAIN A NEURAL NETWORK USING THE GROUPINGS WE CONSTRUCTED\n",
    "1. UNIVERISITY RANKING SIGNAL\n",
    "2. EXPERIENCE SIGNAL\n",
    "3. CATEGORY OF STARTUP\n",
    "4. NUMBER OF INVERSTORS (AND INVESTOR SUCCESS)\n",
    "\n",
    "WE SHALL USE TESTING DATA, VALIDATION DATA, AND SEE THE SUCCESS RATE.\n",
    "'''\n",
    "\n",
    "\n",
    "training_params_binary = ['number_of_founders_grouping_scaling',\n",
    "                          'best_ranking_universities_of_founders_grouping_scaling',\n",
    "                          'best_score_universities_of_founders_grouping_scaling',\n",
    "                          'average_degree_of_founders_grouping_scaling',\n",
    "                          'number_of_prev_title_of_founders_grouping_scaling',\n",
    "                          'managerial_flag_number_of_prev_title_of_founders_grouping_scaling',\n",
    "                          'top_10_categories_flag',\n",
    "                          'number_of_investors_grouping_scaling',\n",
    "                          'average_investor_success',\n",
    "                          'top_10_category_groups_flag',\n",
    "                          'top_10_previous_companies_flag',\n",
    "                          'success_flag']\n",
    "\n",
    "df_for_binary_model_training = df_All_Companies_merged[training_params_binary].copy()\n",
    "df_for_binary_model_training = df_for_binary_model_training.dropna()\n",
    "print('Size of data set is: ', len(df_for_binary_model_training.index))\n",
    "\n",
    "y = df_for_binary_model_training.pop('success_flag').to_frame()\n",
    "print('Size of successful companies in set is: ', (np.sum(y.to_numpy())))\n",
    "X = df_for_binary_model_training\n",
    "\n",
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y,stratify=y, test_size=0.3, random_state = 0)\n",
    "X_test, X_val, y_test, y_val = sklearn.model_selection.train_test_split(X, y,stratify=y, test_size=0.5, random_state = 0)\n",
    "\n",
    "X_train, X_test, y_train, y_test = X_train.to_numpy(), X_test.to_numpy(), y_train.to_numpy(), y_test.to_numpy()\n",
    "X_val, y_val = X_val.to_numpy(), y_val.to_numpy()\n",
    "\n",
    "print('Size train set is {} and number of successful companies in set is {}'.format(len(X_train),np.sum(y_train)) )\n",
    "print('Size test set is {} and number of successful companies in set is {}'.format(len(X_test),np.sum(y_test)) )\n",
    "print('Size validation set is {} and number of successful companies in set is {}'.format(len(X_val),np.sum(y_val)) )\n",
    "\n",
    "\n",
    "number_of_classes = 1\n",
    "number_of_features = X_train.shape[1]\n",
    "model = Sequential()\n",
    "model.add(Dense(2**7, input_dim=number_of_features, activation='relu'))\n",
    "model.add(Dense(2**7, input_dim=number_of_features, activation='relu'))\n",
    "model.add(Dense(2**7, input_dim=number_of_features, activation='relu'))\n",
    "model.add(Dense(2**7, input_dim=number_of_features, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['binary_accuracy'])\n",
    "set_random_state()\n",
    "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs= 500, verbose = 0)\n",
    "\n",
    "eval = model.evaluate(x=X_test, y=y_test)\n",
    "print('The loss on the test set is {} and the binary accuracy is {}'.format(eval[0],eval[1]))\n",
    "\n",
    "df_for_binary_model_training = df_All_Companies_merged[training_params_binary][df_All_Companies_merged['success_flag'] == 1].copy()\n",
    "df_for_binary_model_training = df_for_binary_model_training.dropna()\n",
    "y = df_for_binary_model_training.pop('success_flag').to_frame()\n",
    "X = df_for_binary_model_training\n",
    "\n",
    "eval = model.evaluate(x=X.to_numpy(), y=y.to_numpy())\n",
    "print('The loss on only successful companies set is {} and the binary accuracy is {}'.format(eval[0],eval[1]))\n",
    "\n",
    "df_for_binary_model_training = df_All_Companies_merged[training_params_binary][df_All_Companies_merged['success_flag'] == 0].copy()\n",
    "df_for_binary_model_training = df_for_binary_model_training.dropna()\n",
    "y = df_for_binary_model_training.pop('success_flag').to_frame()\n",
    "X = df_for_binary_model_training\n",
    "\n",
    "eval = model.evaluate(x=X.to_numpy(), y=y.to_numpy())\n",
    "print('The loss on only unsuccessful companies set is {} and the binary accuracy is {}'.format(eval[0],eval[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
